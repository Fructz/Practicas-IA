{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139df7ba-80e0-4053-83d7-39aef07b56c9",
   "metadata": {},
   "source": [
    "# Práctica 5: Clasificador de distancia minima\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704aa952-dacc-400e-b428-4659c189d9f8",
   "metadata": {},
   "source": [
    "## calcCentroids() - Fase de aprendizaje\n",
    "El objetivo de esta función es calcular para cada clase su centroide (el punto/vector medio de todos sus datos).\n",
    "\n",
    "La función recibe:  \n",
    "X: una matriz con las características de cada muestra.  \n",
    "- Cada fila = una muestra.   \n",
    "- Cada columna = una característica.  \n",
    "y: un vector con las etiquetas o clases correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0d6d4d6-a4f1-41a7-a618-f41f591fa542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def calcCentroids(X, y):\n",
    "    classes = np.unique(y)\n",
    "    centroids = [] # Lista vacia donde se guardaran los centroides.\n",
    "\n",
    "    for c in classes:\n",
    "        X_c = X[y == c] # Selecciona las muestras de la clase\n",
    "        mu_c = X_c.mean(axis=0) # Calculo del promedio de las muestras\n",
    "        centroids.append(mu_c) # Guarda el centroide en la lista\n",
    "\n",
    "    return classes, np.array(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cbaa64-fb4e-40ae-84f3-998d66f10ad7",
   "metadata": {},
   "source": [
    "`classes = np.unique(y)` devuelve las clases unicas del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8841a97-a489-407c-a953-cd39c9bd2ce9",
   "metadata": {},
   "source": [
    "Posteriormente se ejecutara el bucle que corresponde directamente a la fase de aprendizaje:\n",
    "\n",
    "$$m_k=\\frac{1}{N_E(\\omega_k)}\\sum_{j=1}^{N_E(\\omega_k)} x^{j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abf138-9513-480c-8104-e9aa0c7ce2a9",
   "metadata": {},
   "source": [
    "## predict() - Fase de clasificación\n",
    "El objetivo de esta función es tomar nuevas muestras X y determinar a qué clase pertenecen, comparando cada muestra con todos los centroides y eligiendo el más cercano.\n",
    "\n",
    "La función recibe:  \n",
    "X: matriz con las muestras a clasificar.  \n",
    "classes: array con los nombres o etiquetas de cada clase.    \n",
    "centroids: matriz donde cada fila es el centroide de cada clase.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3444ad0a-d15f-4d82-8150-1ee21da8606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, classes, centroids):\n",
    "    X = np.asarray(X)\n",
    "    centroids = np.asarray(centroids)\n",
    "\n",
    "    distances = np.linalg.norm(X[:, None, :] - centroids[None, :, :], axis=2)\n",
    "    minIndex = np.argmin(distances, axis=1) # Distancia minima de cada fila\n",
    "    return classes[minIndex]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5013f29-02df-40bd-b818-af5f86abe76c",
   "metadata": {},
   "source": [
    "`distances = np.linalg.norm(X[:, None, :] - centroids[None, :, :], axis=2)` Esta parte del codigo es el responsable de calcular la distancia euclidiana entre cada muestra y cada centroide.\n",
    "$$d( \\tilde{x}, m_k) = \\sqrt{\\sum_{i=1}^{n}(\\tilde{x}_i-m_{ki})^2}$$\n",
    "El resultado que arroja es una matriz de tamaño (n_muestras, n_clases) donde en cada posición [i][j] se guarda la distancia de la muestra i al centroide de la clase k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92dc8c6-67e6-450e-b0f7-29c1c2e1d02e",
   "metadata": {},
   "source": [
    "Posteriormente con `minIndex = np.argmin(distances, axis=1)` se hace la busqueda del indice del centroide más cercano para cada muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654be4d8-90b7-4cdb-b66a-567f1de86639",
   "metadata": {},
   "source": [
    "## showConfusionMatrix() \n",
    "Esta función nos permite comparar ambas y ver cuántas veces tu modelo acertó o se confundio entre clases.  \n",
    "La función recibe:  \n",
    "y_true: etiquetas reales  \n",
    "y_pred: etiquetas que predijo el modelo  \n",
    "classes: lista con las clases posibles, para ordenar la matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdfe99ed-f56e-49b3-bbdc-110938c01841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showConfusionMatrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(pd.DataFrame(cm,\n",
    "                       index=[f\"Real {c}\" for c in classes],\n",
    "                       columns=[f\"Pred {c}\" for c in classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a0584-86b5-4978-90a2-efc0ab273ef3",
   "metadata": {},
   "source": [
    "# Función principal\n",
    "### Carga y limpieza del dataset\n",
    "def main():\n",
    "    df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    maskValidRows = ~X.isna().any(axis=1)\n",
    "    X = X[maskValidRows]\n",
    "    y = y[maskValidRows]\n",
    "\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "\n",
    "    print(\"Dataset successfully loaded\")\n",
    "    print(\"Total size:\", X.shape[0], \"Samples,\", X.shape[1], \"Features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50369353-2794-4aea-bd07-8c47f7ef0924",
   "metadata": {},
   "source": [
    "## Hold-Out 70/30\n",
    "Se aplica el metodo de validación Hold-Out 70/30, donde entrenamos al modelo en el 70% y lo evaluamos una sola vez en el 30% que no vio durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a166f4-a239-41d8-b544-fe01345bd6e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=0, stratify=y\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c0df56-0117-429d-8d25-2aa06e983652",
   "metadata": {},
   "source": [
    "### Normalización\n",
    "Aplicamos normalización con uso de la función StandardScale.  \n",
    "`fit_transform` en `X_train` Calcula la media y desviación estandar de cada caracteristica usando solo el conjunto de entrenamiento\n",
    "\n",
    "`transform` en `X_test` no recalcula media ni sigma, solamente aplica las del entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a666aa-5def-4ec1-a3b4-6d86bdc90051",
   "metadata": {},
   "source": [
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31408d-d050-46c3-b4aa-ca45c7568064",
   "metadata": {},
   "source": [
    "### Entrenamiento y predicción (usando el clasficador)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67945908-c57e-4c92-aa9e-797fc6b675a8",
   "metadata": {},
   "source": [
    "    classes, centroids = calcCentroids(X_train, y_train)\n",
    "    y_pred = predict(X_test, classes, centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff73286-2269-4cd4-8625-e36083a34c0b",
   "metadata": {},
   "source": [
    "### Accuracy (medida de desempeño)\n",
    "Aqui se calcula la proporción de predicciones correctas y se muestra la matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08d7e1-1d47-4ba8-8608-7429fcc8a362",
   "metadata": {},
   "source": [
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n============= 70/30 Hold-Out Results =============\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    showConfusionMatrix(y_test, y_pred, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251fe3aa-3f7e-46ff-8b93-c1da550ae7d5",
   "metadata": {},
   "source": [
    "### 10-Fold Cross Validation\n",
    "En este bloque de codigo lo que realiza el KFold es dividir nuestro dataset en 10 partes aproximadamente del mismo tamaño.  \n",
    "En cada iteración, tomamos 1 fold como test y los 9 restantes como entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ccc747-1f49-4aac-a5d3-49d3f9954edf",
   "metadata": {},
   "source": [
    "   `kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    accuracies = []`\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X), start=1):\n",
    "        # Extraemos los datos correspondientes al fold.\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Normalizamos por fold (Ajustado solamente al entrenamiento del fold)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold = scaler.fit_transform(X_train)\n",
    "        X_test_fold = scaler.transform(X_test)\n",
    "\n",
    "        # Entrenamiento y preddición\n",
    "        classes, centroids = calcCentroids(X_train_fold, y_train)\n",
    "        y_pred = predict(X_test_fold, classes, centroids)\n",
    "\n",
    "        # Calculo del desempeño para este fold\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "        print(f\"Fold {fold}: Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddcb9b-f3a0-4f9a-abb4-9bef35fdbe80",
   "metadata": {},
   "source": [
    "Para finalizar mostramos el desempeño promedio de los 10 folds y la variación del desempeño entre folds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea4b72-9099-45c5-9fed-e82c500f9aed",
   "metadata": {},
   "source": [
    "    print(\"\\n============= 10-Fold Cross Validation Results =============\")\n",
    "    print(f\"Accuracy average: {np.mean(accuracies):.4f}\")\n",
    "    print(f\"Standard deviation: {np.std(accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f70463f-3344-420c-9539-c4667b0b98a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully loaded\n",
      "Total size: 150 Samples, 5 Features\n",
      "\n",
      "============= 70/30 Hold-Out Results =============\n",
      "Accuracy: 0.9556\n",
      "\n",
      "Confusion Matrix:\n",
      "                      Pred Iris-setosa  Pred Iris-versicolor  \\\n",
      "Real Iris-setosa                    15                     0   \n",
      "Real Iris-versicolor                 0                    14   \n",
      "Real Iris-virginica                  0                     1   \n",
      "\n",
      "                      Pred Iris-virginica  \n",
      "Real Iris-setosa                        0  \n",
      "Real Iris-versicolor                    1  \n",
      "Real Iris-virginica                    14  \n",
      "Fold 1: Accuracy = 0.9333\n",
      "Fold 2: Accuracy = 1.0000\n",
      "Fold 3: Accuracy = 1.0000\n",
      "Fold 4: Accuracy = 0.8667\n",
      "Fold 5: Accuracy = 0.9333\n",
      "Fold 6: Accuracy = 1.0000\n",
      "Fold 7: Accuracy = 0.9333\n",
      "Fold 8: Accuracy = 1.0000\n",
      "Fold 9: Accuracy = 0.9333\n",
      "Fold 10: Accuracy = 1.0000\n",
      "\n",
      "============= 10-Fold Cross Validation Results =============\n",
      "Accuracy average: 0.9600\n",
      "Standard deviation: 0.0442\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    maskValidRows = ~X.isna().any(axis=1)\n",
    "    X = X[maskValidRows]\n",
    "    y = y[maskValidRows]\n",
    "\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "\n",
    "    print(\"Dataset successfully loaded\")\n",
    "    print(\"Total size:\", X.shape[0], \"Samples,\", X.shape[1], \"Features\")\n",
    "\n",
    "    # Hold-Out split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=0, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale using only training data (best practice)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    classes, centroids = calcCentroids(X_train, y_train)\n",
    "    y_pred = predict(X_test, classes, centroids)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n============= 70/30 Hold-Out Results =============\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    showConfusionMatrix(y_test, y_pred, classes)\n",
    "\n",
    "    # 10-Fold Cross Validation (simple version: scaling outside per fold)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    accuracies = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X), start=1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold = scaler.fit_transform(X_train)\n",
    "        X_test_fold = scaler.transform(X_test)\n",
    "\n",
    "        classes, centroids = calcCentroids(X_train_fold, y_train)\n",
    "        y_pred = predict(X_test_fold, classes, centroids)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "        print(f\"Fold {fold}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "    print(\"\\n============= 10-Fold Cross Validation Results =============\")\n",
    "    print(f\"Accuracy average: {np.mean(accuracies):.4f}\")\n",
    "    print(f\"Standard deviation: {np.std(accuracies):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e97ed-3335-4d8b-ac87-f0cb119b5f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d6547-0861-4923-b32d-58939aa5e67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81826cc-4b7c-49cf-91ae-8ecc27262d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
